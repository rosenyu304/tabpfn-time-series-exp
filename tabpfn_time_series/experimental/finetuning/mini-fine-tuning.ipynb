{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 22:24:03 - INFO - PyTorch version 2.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "HF_DATASET_REPO_NAME = \"liamsbhoo/GiftEvalPretrain\"\n",
    "# get_dataset_config_names(HF_DATASET_REPO_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 22:24:06 - INFO - Loading datasets: ['borealis', 'wind_power'] from liamsbhoo/GiftEvalPretrain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4ad0cd5f254d3abebff7ca63b19bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/6376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d13354acdbf4ef1ab6c673fc6412f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/6376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 22:24:34 - INFO - Loaded 2 datasets\n",
      "2025-04-28 22:24:34 - INFO -   - borealis: 15 samples\n",
      "2025-04-28 22:24:34 - INFO -   - wind_power: 1 samples\n"
     ]
    }
   ],
   "source": [
    "from tabpfn_time_series.experimental.finetuning.dataset import TabPFNTimeSeriesPretrainDataset, TimeSeriesPretrainConfig\n",
    "\n",
    "pretrain_config = TimeSeriesPretrainConfig()\n",
    "pretrain_config.max_context_length = 500\n",
    "\n",
    "dataset = TabPFNTimeSeriesPretrainDataset(\n",
    "    dataset_repo_name=\"liamsbhoo/GiftEvalPretrain\",\n",
    "    dataset_names=[\n",
    "        \"borealis\",\n",
    "        \"wind_power\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoreload extension to automatically reload modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# This ensures that changes to imported modules are reloaded without restarting the kernel\n",
    "# Particularly useful during development when modifying the dataset.py or other modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shibinhoo/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/runpy.py:126: RuntimeWarning: 'tabpfn_time_series.experimental.finetuning.dataset' found in sys.modules after import of package 'tabpfn_time_series.experimental.finetuning', but prior to execution of 'tabpfn_time_series.experimental.finetuning.dataset'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "%run -m tabpfn_time_series.experimental.finetuning.dataset\n",
    "from tabpfn_time_series.experimental.finetuning.dataset import load_all_ts_datasets\n",
    "\n",
    "all_X, all_y = load_all_ts_datasets(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "regressor_args = dict(\n",
    "    ignore_pretraining_limits=True,\n",
    "    device=\"cpu\",\n",
    "    n_estimators=8,\n",
    "    random_state=0,\n",
    "    inference_precision=torch.float32,\n",
    ")\n",
    "    \n",
    "reg = TabPFNRegressor(\n",
    "    **regressor_args,\n",
    "    differentiable_input=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n",
      "/Users/shibinhoo/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:533: UserWarning: Running on CPU with more than 200 samples may be slow.\n",
      "Consider using a GPU or the tabpfn-client API: https://github.com/PriorLabs/tabpfn-client\n",
      "  check_cpu_warning(self.device, X_raw)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitfn = partial(train_test_split, test_size=0.2, random_state=42)\n",
    "def ts_splitfn(data, **kwargs):\n",
    "    prediction_length = 7\n",
    "    print(\"data type\", type(data))\n",
    "    # Handle pandas DataFrame/Series properly\n",
    "    if isinstance(data, pd.DataFrame) or isinstance(data, pd.Series):\n",
    "        train_data = data.iloc[:-prediction_length]\n",
    "        test_data = data.iloc[-prediction_length:]\n",
    "    else:\n",
    "        # For numpy arrays or other array-like objects\n",
    "        train_data = data[:-prediction_length]\n",
    "        test_data = data[-prediction_length:]\n",
    "    return train_data, test_data\n",
    "\n",
    "splitfn = partial(train_test_split, test_size=0.2, random_state=42)\n",
    "\n",
    "datasets_collection = reg.get_preprocessed_datasets(all_X, all_y, splitfn, max_data_size=1000)\n",
    "# datasets_collection_test = reg.get_preprocessed_datasets(X_tests[0], y_tests[0], splitfn, max_data_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/79 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m (X_trains_preprocessed, X_tests_preprocessed, y_trains_preprocessed,\n\u001b[1;32m     15\u001b[0m  y_test_standardized, cat_ixs, confs, renormalized_criterion, \n\u001b[1;32m     16\u001b[0m  batch_x_test_raw, batch_y_test_raw) \u001b[38;5;241m=\u001b[39m data_batch\n\u001b[1;32m     18\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit_from_preprocessed(X_trains_preprocessed, y_trains_preprocessed, cat_ixs, confs)\n\u001b[0;32m---> 20\u001b[0m averaged_pred_logits , _, _\u001b[38;5;241m=\u001b[39m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tests_preprocessed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [BatchSize, N_test, NumBars]  \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/regressor.py:704\u001b[0m, in \u001b[0;36mTabPFNRegressor.forward\u001b[0;34m(self, X, use_inference_mode)\u001b[0m\n\u001b[1;32m    701\u001b[0m outputs: \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    702\u001b[0m borders: \u001b[38;5;28mlist\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor_\u001b[38;5;241m.\u001b[39miter_outputs(\n\u001b[1;32m    705\u001b[0m     X, \n\u001b[1;32m    706\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_,\n\u001b[1;32m    707\u001b[0m     autocast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_autocast_,\n\u001b[1;32m    708\u001b[0m ):\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_temperature \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    711\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax_temperature  \u001b[38;5;66;03m# noqa: PLW2901\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/inference.py:306\u001b[0m, in \u001b[0;36mInferenceEngineBatchedNoPreprocessing.iter_outputs\u001b[0;34m(self, X, device, autocast)\u001b[0m\n\u001b[1;32m    301\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m         torch\u001b[38;5;241m.\u001b[39mautocast(device\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39mautocast),\n\u001b[1;32m    304\u001b[0m         torch\u001b[38;5;241m.\u001b[39minference_mode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode),\n\u001b[1;32m    305\u001b[0m     ):\n\u001b[0;32m--> 306\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_x_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_y_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43monly_return_standard_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcategorical_inds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat_item\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcat_item\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_ix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: C411\u001b[39;49;00m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble_configs[i]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_mode:  \u001b[38;5;66;03m## if inference\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/transformer.py:418\u001b[0m, in \u001b[0;36mPerFeatureTransformer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    417\u001b[0m     style, x, y \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized input. Please follow the doc string.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/transformer.py:626\u001b[0m, in \u001b[0;36mPerFeatureTransformer._forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere should be no NaNs in the encoded x and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour embedded x and y returned the following:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39misnan(embedded_x)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39misnan(embedded_y)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m embedded_y, embedded_x\n\u001b[0;32m--> 626\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedded_input\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_decoder\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membedded_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos_\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b s f+1 e -> b s f+1 e\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# If we are using a decoder\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder:\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/transformer.py:87\u001b[0m, in \u001b[0;36mLayerStack.forward\u001b[0;34m(self, x, half_layers, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[:n_layers]:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecompute_each_layer \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m---> 87\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/utils/checkpoint.py:496\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# Runs pre-forward logic\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[0;32m--> 496\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Runs post-forward logic\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/layer.py:449\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward\u001b[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre-norm implementation is wrong, as the residual should never\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be layer normed here.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m     state \u001b[38;5;241m=\u001b[39m layer_norm(\n\u001b[1;32m    444\u001b[0m         state,\n\u001b[1;32m    445\u001b[0m         allow_inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    446\u001b[0m         save_peak_mem_factor\u001b[38;5;241m=\u001b[39msave_peak_mem_factor,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[0;32m--> 449\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_norm:\n\u001b[1;32m    451\u001b[0m     state \u001b[38;5;241m=\u001b[39m layer_norm(\n\u001b[1;32m    452\u001b[0m         state,\n\u001b[1;32m    453\u001b[0m         allow_inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    454\u001b[0m         save_peak_mem_factor\u001b[38;5;241m=\u001b[39msave_peak_mem_factor,\n\u001b[1;32m    455\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/layer.py:363\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    360\u001b[0m     new_x_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_eval_pos:\n\u001b[0;32m--> 363\u001b[0m     new_x_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn_between_items\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_cache_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     new_x_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/multi_head_attention.py:355\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k_cache \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    339\u001b[0m             batch_size,\n\u001b[1;32m    340\u001b[0m             seqlen_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_cache \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    347\u001b[0m             batch_size,\n\u001b[1;32m    348\u001b[0m             seqlen_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    353\u001b[0m         )\n\u001b[0;32m--> 355\u001b[0m output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_k_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_v_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cached_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mreshape(x_shape_after_transpose[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/memory.py:100\u001b[0m, in \u001b[0;36msupport_save_peak_mem_factor.<locals>.method_\u001b[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_input:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/multi_head_attention.py:504\u001b[0m, in \u001b[0;36mMultiHeadAttention._compute\u001b[0;34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Attention computation.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m q, k, v, kv, qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_qkv(\n\u001b[1;32m    494\u001b[0m     x,\n\u001b[1;32m    495\u001b[0m     x_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_second_set_of_queries\u001b[38;5;241m=\u001b[39muse_second_set_of_queries,\n\u001b[1;32m    503\u001b[0m )\n\u001b[0;32m--> 504\u001b[0m attention_head_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_attention_heads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meinsum(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... h d, h d s -> ... s\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     attention_head_outputs,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w_out,\n\u001b[1;32m    517\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/freiburg-cs/tabpfn-time-series/tabpfn_time_series/experimental/finetuning/tabpfn_private/src/tabpfn/model/multi_head_attention.py:729\u001b[0m, in \u001b[0;36mMultiHeadAttention.compute_attention_heads\u001b[0;34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001b[0m\n\u001b[1;32m    727\u001b[0m     ps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    728\u001b[0m     ps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdropout(ps, dropout_p, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 729\u001b[0m     attention_head_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb q k h, b k h d -> b q h d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attention_head_outputs\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    732\u001b[0m     batch_size,\n\u001b[1;32m    733\u001b[0m     seqlen_q,\n\u001b[1;32m    734\u001b[0m     nhead,\n\u001b[1;32m    735\u001b[0m     d_v,\n\u001b[1;32m    736\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tabpfn-ts-ft/lib/python3.10/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tabpfn.utils import collate_for_tabpfn_dataset\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "train_dl = DataLoader(datasets_collection, batch_size=1, collate_fn=collate_for_tabpfn_dataset)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    batch_iterator = tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for data_batch in batch_iterator:\n",
    "        print(\"helo\")\n",
    "        (X_trains_preprocessed, X_tests_preprocessed, y_trains_preprocessed,\n",
    "         y_test_standardized, cat_ixs, confs, renormalized_criterion, \n",
    "         batch_x_test_raw, batch_y_test_raw) = data_batch\n",
    "\n",
    "        reg.fit_from_preprocessed(X_trains_preprocessed, y_trains_preprocessed, cat_ixs, confs)\n",
    "\n",
    "        averaged_pred_logits , _, _= reg.forward(X_tests_preprocessed) # [BatchSize, N_test, NumBars]  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpfn-ts-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
